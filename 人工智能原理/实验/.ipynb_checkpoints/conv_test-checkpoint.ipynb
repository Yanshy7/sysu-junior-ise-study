{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import reduce\n",
    "import random\n",
    "import torch\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "X_train, Y_train, X_test, Y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28a8fa62ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, init_params=False):\n",
    "        \"\"\"\n",
    "        :param in_channels: (int) the input channel\n",
    "        :param out_channels: (int) the output channel\n",
    "        :param kernel_size: (int) the kernel size\n",
    "        :param stride: (int) the stirde\n",
    "        \"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.input_h = None\n",
    "        self.input_w = None\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "\n",
    "        self.weight_gradient = 0\n",
    "        self.bias_gradient = 0\n",
    "\n",
    "        self.init_params = init_params\n",
    "\n",
    "        self.weight = np.random.randn(self.in_channels, self.out_channels, self.kernel_size, self.kernel_size)\n",
    "        self.bias = np.random.randn(self.out_channels, 1)\n",
    "\n",
    "\n",
    "        # 输入图像的batch_size=N，默认为1\n",
    "        self.batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "    def _forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (N, C_in, H_in, W_in) 通道*高度*宽度\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        self.input_map = x\n",
    "\n",
    "        if not self.init_params:\n",
    "            self.init_params = True\n",
    "            weights_scale = math.sqrt(reduce(lambda x, y: x * y, self.input_map.shape) / self.out_channels)\n",
    "\n",
    "            self.weight = np.random.standard_normal(\n",
    "                size=(self.in_channels, self.out_channels, self.kernel_size, self.kernel_size)) / weights_scale\n",
    "            self.bias = np.random.standard_normal(size=(self.out_channels, 1)) / weights_scale\n",
    "\n",
    "        self.batch_size, _, self.input_h, self.input_w = x.shape\n",
    "\n",
    "        self.out_h = (self.input_h-self.kernel_size)/self.stride + 1\n",
    "        self.out_w = (self.input_w-self.kernel_size)/self.stride + 1\n",
    "        # print('out_h:', self.out_h)\n",
    "        # print('out_w:', self.out_w)\n",
    "\n",
    "        # 图像转换为矩阵，N*(H*W)*(C*K*K)\n",
    "        self.col_images = []\n",
    "\n",
    "        weight_col = self.weight.reshape(self.out_channels, -1)\n",
    "        # N * C_out * H_out * W_out\n",
    "        conv_out = np.zeros((self.batch_size, self.out_channels, self.out_h, self.out_w))\n",
    "        for batch_i in range(self.batch_size):\n",
    "            # 输入的第i个图像C_in*H_in*W_in\n",
    "            image_batch_i = x[batch_i, :]\n",
    "            image_batch_i_col = self.im2col(image_batch_i, self.kernel_size, self.stride)\n",
    "\n",
    "            self.col_images.append(image_batch_i_col)\n",
    "            # print(image_batch_i_col.shape)\n",
    "            # print(weight_col.shape)\n",
    "            conv_out[batch_i] = np.reshape(np.dot(weight_col, np.transpose(image_batch_i_col))+self.bias, (self.out_channels, self.out_h, self.out_w))\n",
    "\n",
    "        self.col_images = np.array(self.col_images)\n",
    "\n",
    "        return conv_out\n",
    "\n",
    "    # 计算梯度过程中同时将误差反向传播计算出来，根据当前误差返回上一误差\n",
    "    def _backward(self, error):\n",
    "        self.error = error\n",
    "        error_col = self.error.reshape(self.batch_size, self.out_channels, -1)\n",
    "        # print('self.col_images.shape:', self.col_images.shape)\n",
    "        # print('error_col.shape:', error_col.shape)\n",
    "        # print('error.shape:', error.shape)\n",
    "\n",
    "        for batch_i in range(self.batch_size):\n",
    "            self.weight_gradient += np.dot(error_col[batch_i], self.col_images[batch_i]).reshape(self.weight.shape)\n",
    "        # 将对应的维度相加，需要将N和最后求和\n",
    "        self.bias_gradient += np.sum(error_col, axis=(0, 2)).reshape(self.bias.shape)\n",
    "        # 反向传播计算上一层error\n",
    "\n",
    "        error_pad = np.pad(self.error, ((0, 0), (0, 0), (self.kernel_size - 1, self.kernel_size - 1), (self.kernel_size - 1, self.kernel_size - 1)), 'constant', constant_values=0)\n",
    "        # print('error_pad.shape:', error_pad.shape)\n",
    "        # print('error:', error)\n",
    "        # print('error_pad:', error_pad)\n",
    "\n",
    "        weight_flip = self.weight[:, :, ::-1, ::-1]\n",
    "        weight_flip = np.swapaxes(weight_flip, 0, 1)\n",
    "        weight_flip_col = weight_flip.reshape(self.in_channels, -1)\n",
    "        # print('weight_flip_col.shape:', weight_flip_col.shape)\n",
    "\n",
    "\n",
    "        next_error = np.zeros((self.batch_size, self.in_channels, self.input_h, self.input_w))\n",
    "        for batch_i in range(self.batch_size):\n",
    "            # 输入的第i个图像C_in*H_in*W_in\n",
    "            error_pad_image_batch_i = error_pad[batch_i, :]\n",
    "            error_pad_image_batch_i_col = self.im2col(error_pad_image_batch_i, self.kernel_size, self.stride)\n",
    "            # print('error_pad_image_batch_i_col.shape:', error_pad_image_batch_i_col.shape)\n",
    "            next_error[batch_i] = np.reshape(np.dot(weight_flip_col, np.transpose(error_pad_image_batch_i_col)), (self.in_channels, self.input_h, self.input_w))\n",
    "\n",
    "\n",
    "        # print('error_pad_image_col.shape:', error_pad_image_col.shape)\n",
    "        # print('error_pad_image_col.shape:', error_pad_image_col.shape)\n",
    "        # next_error = np.dot(error_pad_image_col, np.transpose(weight_flip_col)).reshape(self.batch_size, self.in_channels, self.input_h, self.input_w)\n",
    "        # print('next_error.shape:', next_error.shape)\n",
    "        #\n",
    "        # conv_out[batch_i] = np.reshape(np.dot(weight_col, np.transpose(image_batch_i_col)) + self.bias,\n",
    "        #                                (self.out_channels, self.out_h, self.out_w))\n",
    "\n",
    "        return next_error\n",
    "        \n",
    "    def im2col(self, image, ksize, stride):\n",
    "        # image is a 3d tensor([channel, height, width])\n",
    "        img_cols = None\n",
    "        for channel_i in range(image.shape[0]):\n",
    "            img_channel_i = img[channnel_i,:]\n",
    "            img_channel_i_cols = []\n",
    "            for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "                for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                    col = img_channel_i[i:i + ksize, j:j + ksize].reshape([-1])\n",
    "                    img_channel_i_cols.append(col)\n",
    "            img_channel_i_cols = np.array(img_channel_i_cols)\n",
    "        if img_col is None:\n",
    "            img_cols = img_channel_i_cols\n",
    "        else:\n",
    "            img_cols = np.hstack((img_cols, img_channel_i_cols))\n",
    "        return img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.83244264, 0.21233911, 0.18182497],\n",
       "        [0.18340451, 0.30424224, 0.52475643],\n",
       "        [0.43194502, 0.29122914, 0.61185289]],\n",
       "\n",
       "       [[0.13949386, 0.29214465, 0.36636184],\n",
       "        [0.45606998, 0.78517596, 0.19967378],\n",
       "        [0.51423444, 0.59241457, 0.04645041]],\n",
       "\n",
       "       [[0.60754485, 0.17052412, 0.06505159],\n",
       "        [0.94888554, 0.96563203, 0.80839735],\n",
       "        [0.30461377, 0.09767211, 0.68423303]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((3,3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(image, ksize, stride):\n",
    "    # image is a 3d tensor([channel, height, width])\n",
    "    img_cols = None\n",
    "    for channel_i in range(image.shape[0]):\n",
    "        img_channel_i = img[channnel_i,:]\n",
    "        img_channel_i_cols = []\n",
    "        for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "            for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                col = img_channel_i[i:i + ksize, j:j + ksize].reshape([-1])\n",
    "                img_channel_i_cols.append(col)\n",
    "        img_channel_i_cols = np.array(img_channel_i_cols)\n",
    "    if img_col is None:\n",
    "        img_cols = img_channel_i_cols\n",
    "    else:\n",
    "        img_cols = np.hstack((img_cols, img_channel_i_cols))\n",
    "    return img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(im2col(a,2,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.02155219, -0.16175539],\n",
       "         [-0.5336488 , -0.00552786]],\n",
       "\n",
       "        [[-0.22945045,  0.38934891],\n",
       "         [-1.26511911,  1.09199226]],\n",
       "\n",
       "        [[ 2.77831304,  1.19363972],\n",
       "         [ 0.21863832,  0.88176104]],\n",
       "\n",
       "        [[-1.00908534, -1.58329421],\n",
       "         [ 0.77370042, -0.53814166]],\n",
       "\n",
       "        [[-1.3466781 , -0.88059127],\n",
       "         [-1.1305523 ,  0.13442888]],\n",
       "\n",
       "        [[ 0.58212279,  0.88774846],\n",
       "         [ 0.89433233,  0.7549978 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.20716589, -0.62347739],\n",
       "         [-1.50815329,  1.09964698]],\n",
       "\n",
       "        [[-0.17773212, -0.41038331],\n",
       "         [ 1.17971634, -0.89820794]],\n",
       "\n",
       "        [[ 0.83479542,  0.29656138],\n",
       "         [-1.03782988, -0.07580375]],\n",
       "\n",
       "        [[ 0.97296353,  0.79559546],\n",
       "         [ 1.49543425,  0.33818125]],\n",
       "\n",
       "        [[ 3.37229625, -0.92039081],\n",
       "         [-0.39863839, -0.06086409]],\n",
       "\n",
       "        [[-1.41875046,  1.04249162],\n",
       "         [ 0.90353249,  0.01900033]]],\n",
       "\n",
       "\n",
       "       [[[-0.53441645, -1.49505387],\n",
       "         [-0.78925833,  0.74371128]],\n",
       "\n",
       "        [[-0.21216142, -0.42686879],\n",
       "         [ 0.50144833,  1.15818665]],\n",
       "\n",
       "        [[ 0.25711687,  0.3145129 ],\n",
       "         [ 1.37186213,  0.17555329]],\n",
       "\n",
       "        [[-0.30928855,  0.6731255 ],\n",
       "         [-0.25663018, -0.36782572]],\n",
       "\n",
       "        [[ 1.27373362, -0.29195267],\n",
       "         [-2.65517605,  0.34551794]],\n",
       "\n",
       "        [[-0.39551645, -0.28913686],\n",
       "         [ 0.45293633, -0.16606091]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.standard_normal((3,6,2,2))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.reshape(6,-1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
