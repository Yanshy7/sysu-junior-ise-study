{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import reduce\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x263eb954fc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        self.W = {'val': np.random.standard_normal((in_channel,out_channel)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(out_channel), 'grad': 0}\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.cache = X\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        X = self.cache\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "        self.b['grad'] = np.sum(dout, axis=0)\n",
    "#         self.update()\n",
    "        return dX\n",
    "    \n",
    "    def update(self, lr=0.001):\n",
    "        self.W['val'] -= lr*self.W['grad']\n",
    "        self.b['val'] -= lr*self.b['grad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, init_params=False):\n",
    "        \"\"\"\n",
    "        :param in_channels: (int) the input channel\n",
    "        :param out_channels: (int) the output channel\n",
    "        :param kernel_size: (int) the kernel size\n",
    "        :param stride: (int) the stirde\n",
    "        \"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.input_h = None\n",
    "        self.input_w = None\n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "\n",
    "        self.weight_gradient = 0\n",
    "        self.bias_gradient = 0\n",
    "\n",
    "        self.init_params = init_params\n",
    "\n",
    "        self.W = {'val': np.random.randn(self.in_channels, self.out_channels, self.kernel_size, self.kernel_size), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(self.out_channels, 1), 'grad': 0}\n",
    "\n",
    "\n",
    "        # 输入图像的batch_size=N，默认为1\n",
    "        self.batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (N, C_in, H_in, W_in) 通道*高度*宽度\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        self.input_map = x\n",
    "\n",
    "        if not self.init_params:\n",
    "            self.init_params = True\n",
    "            weights_scale = math.sqrt(reduce(lambda x, y: x * y, self.input_map.shape) / self.out_channels)\n",
    "\n",
    "            self.W['val'] = np.random.standard_normal(\n",
    "                size=(self.in_channels, self.out_channels, self.kernel_size, self.kernel_size)) / weights_scale\n",
    "            self.b['val'] = np.random.standard_normal(size=(self.out_channels, 1)) / weights_scale\n",
    "\n",
    "        self.batch_size, _, self.input_h, self.input_w = x.shape\n",
    "\n",
    "        self.out_h = int((self.input_h-self.kernel_size)/self.stride + 1)\n",
    "        self.out_w = int((self.input_w-self.kernel_size)/self.stride + 1)\n",
    "        # print('out_h:', self.out_h)\n",
    "        # print('out_w:', self.out_w)\n",
    "\n",
    "        # 图像转换为矩阵，N*(H*W)*(C*K*K)\n",
    "        self.col_images = []\n",
    "\n",
    "        weight_col = self.W['val'].reshape(self.out_channels, -1)\n",
    "        # N * C_out * H_out * W_out\n",
    "        conv_out = np.zeros((self.batch_size, self.out_channels, self.out_h, self.out_w))\n",
    "        for batch_i in range(self.batch_size):\n",
    "            # 输入的第i个图像C_in*H_in*W_in\n",
    "            image_batch_i = x[batch_i, :]\n",
    "            image_batch_i_col = self.im2col(image_batch_i, self.kernel_size, self.stride)\n",
    "\n",
    "            self.col_images.append(image_batch_i_col)\n",
    "            # print(image_batch_i_col.shape)\n",
    "            # print(weight_col.shape)\n",
    "            conv_out[batch_i] = np.reshape(np.dot(weight_col, np.transpose(image_batch_i_col))+self.b['val'], (self.out_channels, self.out_h, self.out_w))\n",
    "\n",
    "        self.col_images = np.array(self.col_images)\n",
    "\n",
    "        return conv_out\n",
    "\n",
    "    # 计算梯度过程中同时将误差反向传播计算出来，根据当前误差返回上一误差\n",
    "    def backward(self, error):\n",
    "        self.error = error\n",
    "        error_col = self.error.reshape(self.batch_size, self.out_channels, -1)\n",
    "        # print('self.col_images.shape:', self.col_images.shape)\n",
    "        # print('error_col.shape:', error_col.shape)\n",
    "        # print('error.shape:', error.shape)\n",
    "\n",
    "        for batch_i in range(self.batch_size):\n",
    "            self.W['grad'] += np.dot(error_col[batch_i], self.col_images[batch_i]).reshape(self.W['val'].shape)\n",
    "        # 将对应的维度相加，需要将N和最后求和\n",
    "        self.b['grad'] += np.sum(error_col, axis=(0, 2)).reshape(self.b['val'].shape)\n",
    "        # 反向传播计算上一层error\n",
    "\n",
    "        error_pad = np.pad(self.error, ((0, 0), (0, 0), (self.kernel_size - 1, self.kernel_size - 1), (self.kernel_size - 1, self.kernel_size - 1)), 'constant', constant_values=0)\n",
    "        # print('error_pad.shape:', error_pad.shape)\n",
    "        # print('error:', error)\n",
    "        # print('error_pad:', error_pad)\n",
    "\n",
    "        weight_flip = self.W['val'][:, :, ::-1, ::-1]\n",
    "        weight_flip = np.swapaxes(weight_flip, 0, 1)\n",
    "        weight_flip_col = weight_flip.reshape(self.in_channels, -1)\n",
    "        # print('weight_flip_col.shape:', weight_flip_col.shape)\n",
    "\n",
    "\n",
    "        next_error = np.zeros((self.batch_size, self.in_channels, self.input_h, self.input_w))\n",
    "        for batch_i in range(self.batch_size):\n",
    "            # 输入的第i个图像C_in*H_in*W_in\n",
    "            error_pad_image_batch_i = error_pad[batch_i, :]\n",
    "            error_pad_image_batch_i_col = self.im2col(error_pad_image_batch_i, self.kernel_size, self.stride)\n",
    "            # print('error_pad_image_batch_i_col.shape:', error_pad_image_batch_i_col.shape)\n",
    "            next_error[batch_i] = np.reshape(np.dot(weight_flip_col, np.transpose(error_pad_image_batch_i_col)), (self.in_channels, self.input_h, self.input_w))\n",
    "\n",
    "\n",
    "        return next_error\n",
    "    \n",
    "    def im2col(self, image, ksize, stride):\n",
    "        # image is a 3d tensor([channel, height, width])\n",
    "        image_col = []\n",
    "        for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "            for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                col = image[:,i:i + ksize, j:j + ksize].reshape([-1])\n",
    "                image_col.append(col)\n",
    "        image_col = np.array(image_col)\n",
    "        return image_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weight_size = (in_channels, out_channels, kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.cache = 0\n",
    "        \n",
    "        self.W = {'val': np.random.standard_normal((self.weight_size)), 'grad': np.zeros(self.weight_size)}\n",
    "        self.b = {'val': np.random.standard_normal(out_channels), 'grad': np.zeros(out_channels)}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        (N,Cin,H,W) = x.shape\n",
    "        self.input_shape = x.shape\n",
    "        H_ = int((H - self.kernel_size) / self.stride + 1)\n",
    "        W_ = int((W - self.kernel_size) / self.stride + 1)\n",
    "        col_weights = self.W['val'].transpose(1,0,2,3).reshape([self.out_channels,-1]).T\n",
    "        self.col_image = []\n",
    "        conv_out = np.zeros((N,self.out_channels,H_,W_))\n",
    "        for i in range(N):\n",
    "            img_i = x[i]\n",
    "            self.col_image_i = self.im2col(img_i,self.kernel_size,self.stride)\n",
    "#             print(self.col_image_i.shape)\n",
    "            conv_out[i] = np.reshape(np.dot(self.col_image_i, col_weights) + self.b['val'],(H_,W_,-1)).transpose(2,0,1)\n",
    "            self.col_image.append(self.col_image_i)\n",
    "        self.col_image = np.array(self.col_image)\n",
    "        return conv_out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        (N,Cout,H_,W_) = dout.shape\n",
    "        col_dout = dout.reshape((N,Cout,-1))\n",
    "        \n",
    "        for i in range(self.input_shape[0]):\n",
    "            self.W['grad'] += np.dot(col_dout[i], self.col_image[i]).reshape(self.W['val'].shape)\n",
    "        self.b['grad'] += np.sum(col_dout,axis=(0,2)).reshape(self.b['val'].shape)\n",
    "        \n",
    "        dout_pad = np.pad(dout, ((0, 0), (0, 0), (self.kernel_size - 1, self.kernel_size - 1), (self.kernel_size - 1, self.kernel_size - 1)), 'constant', constant_values=0)\n",
    "        \n",
    "        weight_flip = self.W['val'][:,:,::-1,::-1]\n",
    "        weight_flip = np.swapaxes(weight_flip, 0, 1)\n",
    "        weight_flip_col = weight_flip.reshape(self.in_channels, -1)\n",
    "        \n",
    "        next_dout =  np.zeros((N, self.in_channels, self.input_shape[2], self.input_shape[3]))\n",
    "        for i in range(N):\n",
    "            dout_pad_image_batch_i = dout_pad[i,:]\n",
    "            dout_pad_image_batch_i_col = self.im2col(dout_pad_image_batch_i , self.kernel_size, self.stride)\n",
    "            next_dout[i] = np.reshape(np.dot(weight_flip_col, np.transpose(dout_pad_image_batch_i_col)), (self.in_channels, self.input_shape[2], self.input_shape[3]))\n",
    "        \n",
    "        return next_dout\n",
    "        \n",
    "    def im2col(self, image, ksize, stride):\n",
    "        # image is a 3d tensor([channel, height, width])\n",
    "        image_col = []\n",
    "        for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "            for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                col = image[:,i:i + ksize, j:j + ksize].reshape([-1])\n",
    "                image_col.append(col)\n",
    "        image_col = np.array(image_col)\n",
    "        return image_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, kernel_size=2, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.mask = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        (N,Cin,H,W) = x.shape\n",
    "        H_ = int(H/self.kernel_size)\n",
    "        W_ = int(W/self.kernel_size)\n",
    "        out = np.zeros((N, Cin, H_, W_))\n",
    "        self.mask = np.zeros(x.shape)\n",
    "        for n in range(N):\n",
    "            for cin in range(Cin):\n",
    "                for h in range(0, H, self.stride):\n",
    "                    for w in range(0, W, self.stride):\n",
    "                        out[n,cin,h//self.stride,w//self.stride] = np.max(x[n,cin,h:h + self.kernel_size, w:w + self.kernel_size])\n",
    "                        i,j = np.unravel_index(np.argmax(x[n,cin,h:h + self.kernel_size, w:w + self.kernel_size]),(self.kernel_size,self.kernel_size))\n",
    "                        self.mask[n,cin,i+h,j+w] = 1\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        return np.repeat(np.repeat(dout, self.stride, axis=2), self.stride, axis=3) * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "        self.loss = 0\n",
    "        \n",
    "    def forward(self, prediction):\n",
    "        self.prediction = prediction\n",
    "        exp_prediction = np.zeros(prediction.shape)\n",
    "        self.softmax = np.zeros(prediction.shape)\n",
    "        for n in range(prediction.shape[0]):\n",
    "            prediction[n, :] -= np.max(prediction[n, :]) # 防止上溢出\n",
    "            exp_prediction[n] = np.exp(prediction[n])\n",
    "            self.softmax[n] = exp_prediction[n]/np.sum(exp_prediction[n])\n",
    "    \n",
    "        return self.softmax\n",
    "    \n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss():\n",
    "    def __init__(self):\n",
    "        self.loss = 0\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        loss = 0.0\n",
    "        N = pred.shape[0]\n",
    "        for n in range(N):\n",
    "            label = target[n]\n",
    "            if pred[n,label] == 0:\n",
    "                loss += 500\n",
    "            else:\n",
    "                self.loss += -np.log(pred[n,label])\n",
    "        return self.loss / N\n",
    "        \n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        nllLoss = NLLLoss()\n",
    "        prob = softmax.forward(Y_pred)\n",
    "        loss = nllLoss.forward(prob, Y_true)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_true] -= 1\n",
    "        return loss, dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    ReLU activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build ReLU\")\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(\"ReLU: _forward\")\n",
    "        out = np.maximum(0, X)\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #print(\"ReLU: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.array(dout, copy=True)\n",
    "        dX[X <= 0] = 0\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout():\n",
    "    \"\"\"\n",
    "    Dropout layer\n",
    "    \"\"\"\n",
    "    def __init__(self, p=1):\n",
    "        self.cache = None\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, X):\n",
    "        M = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "        self.cache = X, M\n",
    "        return X*M\n",
    "\n",
    "    def backward(self, dout):\n",
    "        X, M = self.cache\n",
    "        dX = dout*M/self.p\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, params, lr=0.001, reg=0):\n",
    "        self.parameters = params\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "        self.l = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['val'].shape))\n",
    "        self.lr = lr\n",
    "        self.rho = momentum\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.l):\n",
    "            self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "            self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5():\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2d(1, 6, 5)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool2d(2,2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool2d(2,2)\n",
    "        self.FC1 = FC(16*4*4, 120)\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 10)\n",
    "\n",
    "        self.p2_shape = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1.forward(X)\n",
    "        a1 = self.ReLU1.forward(h1)\n",
    "        p1 = self.pool1.forward(a1)\n",
    "        h2 = self.conv2.forward(p1)\n",
    "        a2 = self.ReLU2.forward(h2)\n",
    "        p2 = self.pool2.forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1.forward(fl)\n",
    "        a3 = self.ReLU3.forward(h3)\n",
    "        h4 = self.FC2.forward(a3)\n",
    "        a5 = self.ReLU4.forward(h4)\n",
    "        h5 = self.FC3.forward(a5)\n",
    "        return h5\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = self.FC3.backward(dout)\n",
    "        dout = self.ReLU4.backward(dout)\n",
    "        dout = self.FC2.backward(dout)\n",
    "        dout = self.ReLU3.backward(dout)\n",
    "        dout = self.FC1.backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2.backward(dout)\n",
    "        dout = self.ReLU2.backward(dout)\n",
    "        dout = self.conv2.backward(dout)\n",
    "        dout = self.pool1.backward(dout)\n",
    "        dout = self.ReLU1.backward(dout)\n",
    "        dout = self.conv1.backward(dout)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load()\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% iter: 0, loss: 0.0\n",
      "0.4% iter: 100, loss: 5.2573007056984675\n",
      "0.8% iter: 200, loss: 2.8076540359565034\n",
      "1.2% iter: 300, loss: 2.37710255229967\n",
      "1.6% iter: 400, loss: 2.4293358958074664\n",
      "2.0% iter: 500, loss: 2.2551569163479033\n",
      "2.4% iter: 600, loss: 2.3589515943257995\n",
      "2.8% iter: 700, loss: 2.497553507016275\n",
      "3.2% iter: 800, loss: 2.3079187397358707\n",
      "3.6% iter: 900, loss: 2.363866776393724\n",
      "4.0% iter: 1000, loss: 2.491802817516912\n",
      "4.4% iter: 1100, loss: 2.3929565724138273\n",
      "4.8% iter: 1200, loss: 2.5324280941541715\n",
      "5.2% iter: 1300, loss: 2.1942084877632246\n",
      "5.6% iter: 1400, loss: 2.629242269089605\n",
      "6.0% iter: 1500, loss: 2.3614350027012603\n",
      "6.4% iter: 1600, loss: 2.490293559427645\n",
      "6.8% iter: 1700, loss: 2.463842247293868\n",
      "7.2% iter: 1800, loss: 2.59584643104854\n",
      "7.6% iter: 1900, loss: 2.307354028228683\n",
      "8.0% iter: 2000, loss: 2.250279988247057\n",
      "8.4% iter: 2100, loss: 2.2827229558455886\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "losses = []\n",
    "optim = SGDMomentum(model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "criterion = CrossEntropyLoss()\n",
    "ITER = 25000\n",
    "for i in range(ITER):\n",
    "    # get batch, make onehot\n",
    "    X_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "\n",
    "    # forward, loss, backward, step\n",
    "    X_batch = X_batch.reshape((batch_size, 1, 28, 28))\n",
    "    Y_pred = model.forward(X_batch)\n",
    "#     print(Y_pred)\n",
    "    loss, dout = criterion.get(Y_pred, Y_batch)\n",
    "#     print(dout)\n",
    "    model.backward(dout)\n",
    "    optim.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"%s%% iter: %s, loss: %s\" % (100*i/ITER,i, loss))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weight_size = (in_channels, out_channels, kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.cache = 0\n",
    "        \n",
    "        self.W = {'val': np.random.standard_normal(self.weight_size), 'grad': np.zeros(self.weight_size)}\n",
    "        self.b = {'val': np.random.standard_normal((out_channels,1)), 'grad': np.zeros((out_channels,1))}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        (N,Cin,H,W) = x.shape\n",
    "        self.input_shape = x.shape\n",
    "        H_ = int((H - self.kernel_size) / self.stride + 1)\n",
    "        W_ = int((W - self.kernel_size) / self.stride + 1)\n",
    "        col_weights = self.W['val'].transpose(1,0,2,3).reshape([self.out_channels,-1])\n",
    "        self.col_image = []\n",
    "        conv_out = np.zeros((N,self.out_channels,H_,W_))\n",
    "        for i in range(N):\n",
    "            img_i = x[i,:]\n",
    "            self.col_image_i = self.im2col(img_i,self.kernel_size,self.stride)\n",
    "#             print(self.col_image_i.shape)\n",
    "            conv_out[i] = np.reshape(np.dot(col_weights, np.transpose(self.col_image_i))+self.b['val'], (self.out_channels, H_, W_))\n",
    "            self.col_image.append(self.col_image_i)\n",
    "        self.col_image = np.array(self.col_image)\n",
    "        return conv_out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        (N,Cout,H_,W_) = dout.shape\n",
    "        col_dout = dout.reshape((N,Cout,-1))\n",
    "        \n",
    "        for i in range(self.input_shape[0]):\n",
    "            self.W['grad'] += np.dot(col_dout[i], self.col_image[i]).reshape(self.W['val'].shape)\n",
    "        self.b['grad'] += np.sum(col_dout,axis=(0,2)).reshape(self.b['val'].shape)\n",
    "        \n",
    "        dout_pad = np.pad(dout, ((0, 0), (0, 0), (self.kernel_size - 1, self.kernel_size - 1), (self.kernel_size - 1, self.kernel_size - 1)), 'constant', constant_values=0)\n",
    "        \n",
    "        weight_flip = self.W['val'][:,:,::-1,::-1]\n",
    "        weight_flip = np.swapaxes(weight_flip, 0, 1)\n",
    "        weight_flip_col = weight_flip.reshape(self.in_channels, -1)\n",
    "        \n",
    "        next_dout =  np.zeros((N, self.in_channels, self.input_shape[2], self.input_shape[3]))\n",
    "        for i in range(N):\n",
    "            dout_pad_image_batch_i = dout_pad[i,:]\n",
    "            dout_pad_image_batch_i_col = self.im2col(dout_pad_image_batch_i , self.kernel_size, self.stride)\n",
    "            next_dout[i] = np.reshape(np.dot(weight_flip_col, np.transpose(dout_pad_image_batch_i_col)), (self.in_channels, self.input_shape[2], self.input_shape[3]))\n",
    "        \n",
    "        return next_dout\n",
    "        \n",
    "    def im2col(self, image, ksize, stride):\n",
    "        # image is a 3d tensor([channel, height, width])\n",
    "        image_col = []\n",
    "        for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "            for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                col = image[:,i:i + ksize, j:j + ksize].reshape([-1])\n",
    "                image_col.append(col)\n",
    "        image_col = np.array(image_col)\n",
    "        return image_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = X_train[0:2].reshape(2,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = Conv2d(1,6,5)\n",
    "out = conv2d.forward(batch)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = out.copy() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dout = conv2d.backward(real-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2d = MaxPool2d()\n",
    "out = pool2d.forward(batch)\n",
    "plt.imshow(pool2d.mask[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0,0,:,:].reshape(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
